{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73b69f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/brandm/Documents/Tesis/conflictmodel/conflictmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1515f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# Created on January - 2023\n",
    "# @author: Brandon Minta\n",
    "# -------------------------------------------------------------------------\n",
    "#\n",
    "#   A simulation of a socio-dynamical model of conflicts based on \n",
    "#   \"pay or else\" for setting simple interaction  rules among agents.  \n",
    "#\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import path_search as pth\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "\n",
    "#Constants \n",
    "c = 0.1                         # commitment fluctuation \n",
    "l_wealth, u_wealth = 300, 500   # Wealth limits distribution\n",
    "k = 0.25                        # Tribute \n",
    "r = 20                          # Resource injection\n",
    "q = 250                         #Tribute\n",
    "\n",
    "#Functions\n",
    "def resources(actor, coalition, matrix, capital):    \n",
    "    \"\"\"\n",
    "    The function calculates the total resources of a coalition\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    actor: int\n",
    "        The actor of interest \n",
    "    coalition: array\n",
    "        Coalition of the actor\n",
    "    matrix: array\n",
    "        Commitment matrix\n",
    "    capital: dictionary\n",
    "        Capital of each member\n",
    "    \n",
    "    return\n",
    "    ------\n",
    "    money: float\n",
    "        The total resources of the coalition\n",
    "        \n",
    "    \"\"\"\n",
    "    money = 0\n",
    "    for i in coalition:\n",
    "        money += matrix[i][actor] * capital[i]        \n",
    "    return money   \n",
    "\n",
    "def wealth():\n",
    "    # This function assigns a random value from upper and lower wealth limits\n",
    "    return random.randrange(l_wealth,u_wealth,1) \n",
    "    \n",
    "def vulnerability(r_i, r_j):\n",
    "    \"\"\"\n",
    "    The function computes the vulnerability of agent j with respect to agent i\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    r_i: float\n",
    "        Resources of i's coalition\n",
    "    r_j: float\n",
    "        Resources of j's coalition\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The vulnerability of j with respect to i\n",
    "    \"\"\"\n",
    "    return (r_i - r_j) / r_i if r_i > 0 and r_j > 0 else 0\n",
    "\n",
    "def loss(r_i, r_j, contribution):         \n",
    "    \"\"\"\n",
    "    The function calculates agent j's loss of resources, caused by conflict with i\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    r_i: float\n",
    "        Resources of i's coalition  \n",
    "    r_j: float\n",
    "        Resources of j's coalition  \n",
    "    contribution: float\n",
    "        j's contribution of resources to the coalition\n",
    "        \n",
    "    return\n",
    "    -------\n",
    "    float:\n",
    "        Resources loss of j member of it's coalition\n",
    "        \n",
    "    \"\"\"\n",
    "    return k*r_i*(contribution)/r_j\n",
    "  \n",
    "def min_pay(r_j):   \n",
    "    # This function computes the minimum ability to pay of agent j\n",
    "    return q if r_j > q else r_j \n",
    "\n",
    "def activity(M0, M1):\n",
    "    \"\"\"\n",
    "    This function computes the change in the commitment matrix\n",
    "    used by K.Kaneko.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    M0: array matrix (nxn) \n",
    "        Commitment matrix at time t\n",
    "    M1: array matrix (nxn) \n",
    "        Commitment matrix at time t+1 \n",
    "        \n",
    "    return    \n",
    "    ------\n",
    "    float\n",
    "        The activity of the commitment matrix\n",
    "        \n",
    "    \"\"\"\n",
    "    num = M0.shape[0]\n",
    "    new = np.abs(M1 - M0)\n",
    "    return np.sum(new) / ((num - 1) ** 2)\n",
    "\n",
    "def groups_matrix(matrix, grid, indices, attacker,  target) :\n",
    "    \"\"\"\n",
    "    This function generates an array that represents commitments based on two groups\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    matrix: array matrix (NxN) \n",
    "        Commitment matrix\n",
    "    grid: array matrix (LxL) \n",
    "        Geographical matrix\n",
    "    indices: dictionary\n",
    "            indices of elements\n",
    "    attacker: int\n",
    "        Selected attacker\n",
    "    target: int\n",
    "        Selected target\n",
    "        \n",
    "    return    \n",
    "    ------\n",
    "    topology: array LxL\n",
    "        Segregated groups\n",
    "        \n",
    "    \"\"\"\n",
    "    topology =  np.copy(grid)\n",
    "    for j in range(len(indices)):\n",
    "        row, col = indices[j]\n",
    "        if matrix[j][attacker] > matrix[j][target]:\n",
    "            topology[row][col] = 2               #attackers\n",
    "        elif matrix[j][attacker] < matrix[j][target]:\n",
    "            topology[row][col] = 3               #defenders\n",
    "            \n",
    "    row_a, col_a = indices[attacker]\n",
    "    row_i, col_i = indices[target]\n",
    "    \n",
    "    topology[row_a][col_a] = 2\n",
    "    topology[row_i][col_i] = 3\n",
    "    \n",
    "    return topology\n",
    "\n",
    "class AccessibilityGrid:\n",
    "    def __init__(self, L):\n",
    "        \"\"\"\n",
    "        Initialize the AccessibilityGrid class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        L: int\n",
    "            Size of the topological grid.\n",
    "        \"\"\"\n",
    "        self.L = L\n",
    "        self.grid = np.zeros((L, L), dtype=int)\n",
    "\n",
    "    def generate_grid(self, density=None):\n",
    "        \"\"\"\n",
    "        Generate an array with a connected grid of valid elements (0's)\n",
    "        surrounded by inaccessible elements (1's) using a specified density of obstacles.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        density: float (optional)\n",
    "            Density of obstacles on the topological grid.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        topology: array LxL\n",
    "            Grid with connected valid elements (0's) and inaccessible elements (1's).\n",
    "        \"\"\"\n",
    "        if density is None:\n",
    "            return self.grid\n",
    "        \n",
    "        self.grid = np.ones((self.L, self.L), dtype=int)\n",
    "        num_obstacles = int(density * self.L * self.L)\n",
    "        valid_elements = self.L * self.L - num_obstacles\n",
    "\n",
    "        # Select a random cell as the origin for expanding valid elements\n",
    "        origin = np.random.randint(self.L), np.random.randint(self.L)\n",
    "\n",
    "        # Expand valid elements from the origin\n",
    "        self._expand_valid_elements(origin, valid_elements)\n",
    "\n",
    "        return self.grid\n",
    "\n",
    "    def _expand_valid_elements(self, origin, valid_elements):\n",
    "        \"\"\"\n",
    "        Expand valid elements (0's) from the given origin in the grid until reaching the specified count\n",
    "        using a Monte Carlo method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        origin: tuple\n",
    "            Coordinates (row, col) of the origin cell.\n",
    "        valid_elements: int\n",
    "            Number of valid elements (0's) to reach.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Number of valid elements added.\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "\n",
    "        while count < valid_elements:\n",
    "            # Randomly select a neighbor cell\n",
    "            neighbors = [\n",
    "                [(origin[0] - 1) % self.L, origin[1]],    # Up\n",
    "                [(origin[0] + 1) % self.L, origin[1]],    # Down\n",
    "                [origin[0], (origin[1] - 1) % self.L],    # Left\n",
    "                [origin[0], (origin[1] + 1) % self.L]     # Right\n",
    "            ]\n",
    "            neighbor_row, neighbor_col = neighbors[np.random.randint(4)]\n",
    "\n",
    "            if self.grid[neighbor_row, neighbor_col] == 1:\n",
    "                # Add the neighbor cell as a valid element\n",
    "                self.grid[neighbor_row, neighbor_col] = 0\n",
    "                count += 1\n",
    "\n",
    "            # Update the origin to the neighbor cell\n",
    "            origin = (neighbor_row, neighbor_col)\n",
    "\n",
    "class DictionaryUpdater:\n",
    "    increment = r\n",
    "    @classmethod\n",
    "    def update_dic(cls, resources_dic):\n",
    "        # This method increases the values of the resources of every agent\n",
    "        for key in resources_dic:\n",
    "            resources_dic[key] += cls.increment\n",
    "\n",
    "class Simulation:\n",
    "    def __init__(self, L, years, density=None):\n",
    "        self.L = L\n",
    "        self.years = years\n",
    "        self.density = density\n",
    "        self.data = pd.DataFrame(columns=['Attackers', 'Defenders', 'Activity', 'Status', 'TCL', 'ACL', 'Active', 'Target'])\n",
    "        self.matrix_list = []\n",
    "        access_grid = AccessibilityGrid(self.L)\n",
    "        self.grid = access_grid.generate_grid(self.density)\n",
    "        self.actors_pos =self.get_actor_positions()\n",
    "        self.N = len(self.actors_pos)\n",
    "        self.capital ={i: round(wealth(), 3) for i in range(self.N)}\n",
    "        self.M = np.identity(self.N) \n",
    "        self.old_M = np.copy(self.M)\n",
    "\n",
    "    def get_actor_positions(self):\n",
    "        actors_pos = {}\n",
    "        for idx, (row, col) in enumerate(np.argwhere(self.grid == 0)):\n",
    "            actor_index = idx\n",
    "            actors_pos[actor_index] = (row, col)\n",
    "        return actors_pos\n",
    "\n",
    "    def simulate_activation(self, land_combat):\n",
    "        class Status:\n",
    "            def __init__(self, target, target_alley, target_resources, attacker_alley, attacker_resources, susceptibility):\n",
    "                self.target = target\n",
    "                self.target_alley = target_alley\n",
    "                self.target_resources = target_resources\n",
    "                self.attacker_alley = attacker_alley\n",
    "                self.attacker_resources = attacker_resources\n",
    "                self.susceptibility = susceptibility\n",
    "\n",
    "        def candidates_2d(attacker, capital, M, grid, actors_pos):\n",
    "            current_status = Status(np.nan, np.nan, np.nan, np.nan, np.nan, 0)\n",
    "            L = grid.shape[0]\n",
    "\n",
    "            for i in range(len(self.actors_pos)):\n",
    "                if i == attacker:\n",
    "                    continue\n",
    "                topology = groups_matrix(M, grid, actors_pos, attacker, i)\n",
    "                #The attacker can chose any agent on the grid\n",
    "                if land_combat == False:\n",
    "                    attacker_alley = []\n",
    "                    target_alley = []\n",
    "\n",
    "                    for key, (row, col) in actors_pos.items():\n",
    "                        if topology[row][col] == 2:\n",
    "                            attacker_alley.append(key)\n",
    "                        elif topology[row][col] == 3:\n",
    "                            target_alley.append(key)\n",
    "                #The attacker can only attack if there is a path to connnect with a target  \n",
    "                elif land_combat == True:\n",
    "                    attacker_alley = pth.group(attacker, topology, 2, actors_pos)\n",
    "                    target_neighbors = pth.vicinal(actors_pos,i, L)\n",
    "\n",
    "                    if not any(item in target_neighbors for item in attacker_alley):\n",
    "                        continue\n",
    "\n",
    "                    target_alley = pth.group(i, topology, 3, actors_pos)\n",
    "                \n",
    "                attacker_resources = resources(attacker, attacker_alley, M, capital)\n",
    "                target_resources = resources(i, target_alley, M, capital)\n",
    "\n",
    "                susceptibility_target = vulnerability(attacker_resources, target_resources) * min_pay(capital[i])\n",
    "                if susceptibility_target > current_status.susceptibility:\n",
    "                    current_status = Status(i, target_alley, target_resources, attacker_alley, attacker_resources,\n",
    "                                            susceptibility_target)\n",
    "            return current_status\n",
    "\n",
    "        def response(attacker, state, capital, M):\n",
    "            target = state.target\n",
    "            target_alley = state.target_alley\n",
    "            target_resources = state.target_resources\n",
    "            attacker_alley = state.attacker_alley\n",
    "            attacker_resources = state.attacker_resources\n",
    "            target_loss, active_loss = 0, 0\n",
    "\n",
    "            if min_pay(capital[target]) > loss(attacker_resources, target_resources, capital[target]):\n",
    "                for i in target_alley:\n",
    "                    offering = M[i][target] * capital[i]\n",
    "                    contribution_loss = loss(attacker_resources, target_resources, offering)\n",
    "                    capital[i] -= contribution_loss\n",
    "                    target_loss += contribution_loss\n",
    "                    for m in target_alley:\n",
    "                        if 1 - c >= M[i][m] >= 0:\n",
    "                            M[i][m] = M[i][m] + c\n",
    "                    for n in attacker_alley:\n",
    "                        if 1 >= M[i][n] >= c:\n",
    "                            M[i][n] = M[i][n] - c\n",
    "                            M[n][i] = M[n][i] - c\n",
    "\n",
    "                for j in attacker_alley:\n",
    "                    offering = M[j][attacker] * capital[j]\n",
    "                    contribution_loss = loss(target_resources, attacker_resources, offering)\n",
    "                    capital[j] -= contribution_loss\n",
    "                    active_loss += contribution_loss\n",
    "                    for l in attacker_alley:\n",
    "                        if 1 - c >= M[j][l] >= 0:\n",
    "                            M[j][l] = M[j][l] + c\n",
    "\n",
    "                return 1, target_loss, active_loss\n",
    "\n",
    "            else:\n",
    "                money = min_pay(capital[target])\n",
    "                capital[target], capital[attacker] = capital[target] - money, capital[attacker] + money\n",
    "                if 1 - c >= M[target][attacker] >= 0:\n",
    "                    M[target][attacker] += c\n",
    "                    M[attacker][target] += c\n",
    "\n",
    "                return 0, money, 0\n",
    "\n",
    "\n",
    "        attacker = random.randrange(0, len(self.actors_pos))\n",
    "        prospect = candidates_2d(attacker, self.capital, self.M, self.grid, self.actors_pos)\n",
    "        tau, alpha = prospect.target_alley, prospect.attacker_alley\n",
    "        if prospect.susceptibility > 0:\n",
    "            decision, t_loss, a_loss = response(attacker, prospect, self.capital, self.M)\n",
    "            return decision, tau, alpha, t_loss, a_loss, attacker, prospect.target\n",
    "        else:\n",
    "            return 0, tau, alpha, 0, 0, attacker, prospect.target\n",
    "\n",
    "    def save_data_to_hdf5(self, file_path, land_combat=True):\n",
    "        with h5py.File(file_path, \"w\") as hdf5_file:\n",
    "            simulation_data = hdf5_file.create_group(\"simulation_data\")\n",
    "\n",
    "            for year in range(self.years):\n",
    "                year_group = simulation_data.create_group(f\"year_{year}\")\n",
    "\n",
    "                for _ in range(self.N // 3):\n",
    "                    status, tau, alpha, t_loss, a_loss, active, target = self.simulate_activation(land_combat)\n",
    "\n",
    "                    # Convert lists to numpy arrays to store them in the HDF5 file\n",
    "                    tau = np.array(tau) if isinstance(tau, list) else np.array([np.nan])\n",
    "                    alpha = np.array(alpha) if isinstance(alpha, list) else np.array([np.nan])\n",
    "\n",
    "                    # Create datasets for each variable and store the data in the corresponding year group\n",
    "                    year_group.create_dataset(\"status\", data=status)\n",
    "                    year_group.create_dataset(\"tau\", data=tau)\n",
    "                    year_group.create_dataset(\"alpha\", data=alpha)\n",
    "                    year_group.create_dataset(\"t_loss\", data=t_loss)\n",
    "                    year_group.create_dataset(\"a_loss\", data=a_loss)\n",
    "                    year_group.create_dataset(\"active\", data=active)\n",
    "                    year_group.create_dataset(\"target\", data=target)\n",
    "                    year_group.create_dataset(\"acti\", data=activity(self.old_M, self.M))\n",
    "\n",
    "                    resources_dataset = year_group.create_dataset(\"resources\", shape=(1,), dtype=h5py.special_dtype(vlen=str))\n",
    "                    resources_dataset[0] = str(self.capital)\n",
    "\n",
    "                    self.old_M = np.round(np.copy(self.M), 1)\n",
    "\n",
    "                DictionaryUpdater.update_dic(self.capital)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6b20084",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 5\n",
    "numbers = 100\n",
    "density = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ca940ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation = Simulation(L, numbers, density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b8d201e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_data_to_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimulation_data.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mland_combat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 387\u001b[0m, in \u001b[0;36mSimulation.save_data_to_hdf5\u001b[0;34m(self, file_path, land_combat)\u001b[0m\n\u001b[1;32m    384\u001b[0m alpha \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(alpha) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(alpha, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mnan])\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# Create datasets for each variable and store the data in the corresponding year group\u001b[39;00m\n\u001b[0;32m--> 387\u001b[0m \u001b[43myear_group\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m year_group\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtau\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39mtau)\n\u001b[1;32m    389\u001b[0m year_group\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39malpha)\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/h5py/_hl/group.py:161\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    158\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    159\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[0;32m--> 161\u001b[0m dsid \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/h5py/_hl/dataset.py:156\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     sid \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[0;32m--> 156\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m \u001b[43mh5d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[1;32m    159\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5d.pyx:87\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "simulation.save_data_to_hdf5( \"simulation_data.h5\", land_combat = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046b33a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e479088",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b673bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Example time series data\n",
    "time_steps = np.arange(0, 10, 1)\n",
    "a_values = np.random.rand(len(time_steps))\n",
    "b_values = np.random.rand(len(time_steps))\n",
    "c_values = np.random.rand(len(time_steps))\n",
    "d_values = np.random.rand(len(time_steps))\n",
    "\n",
    "# Create an HDF5 file\n",
    "with h5py.File('time_series_data.h5', 'w') as file:\n",
    "\n",
    "    # Create datasets for a, b, c, and d values at each time step\n",
    "    file.create_dataset('time_steps', data=time_steps)\n",
    "    file.create_dataset('a', data=a_values)\n",
    "    file.create_dataset('b', data=b_values)\n",
    "    file.create_dataset('c', data=c_values)\n",
    "    file.create_dataset('d', data=d_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7a45ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8a6de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4370725 , 0.58807764, 0.28121882, 0.10897035, 0.68428962,\n",
       "       0.95180569, 0.59557853, 0.91333631, 0.62831627, 0.24473226])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d83a5aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File structure:\n",
      "<HDF5 file \"time_series_data.h5\" (mode r)>\n",
      "\n",
      "Dataset names:\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "time_steps\n",
      "\n",
      "Contents of 'time_steps' dataset:\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "Contents of 'a' dataset:\n",
      "[0.4370725  0.58807764 0.28121882 0.10897035 0.68428962 0.95180569\n",
      " 0.59557853 0.91333631 0.62831627 0.24473226]\n",
      "\n",
      "Contents of 'b' dataset:\n",
      "[0.57762362 0.72649827 0.71342375 0.4149241  0.84626147 0.41351811\n",
      " 0.67576436 0.39717624 0.36667241 0.80972829]\n",
      "\n",
      "Contents of 'c' dataset:\n",
      "[0.74445525 0.7430951  0.1239345  0.86575591 0.08899987 0.40520195\n",
      " 0.23811586 0.52453858 0.24692553 0.08550997]\n",
      "\n",
      "Contents of 'd' dataset:\n",
      "[0.81733923 0.8868622  0.80310184 0.36697989 0.98704167 0.98821564\n",
      " 0.40000744 0.16953862 0.30690707 0.94170291]\n"
     ]
    }
   ],
   "source": [
    "# Open the HDF5 file in read mode\n",
    "with h5py.File('time_series_data.h5', 'r') as file:\n",
    "\n",
    "    # Print the overall structure of the file\n",
    "    print(\"File structure:\")\n",
    "    print(file)\n",
    "\n",
    "    # Print the names of all the datasets in the file\n",
    "    print(\"\\nDataset names:\")\n",
    "    for name in file:\n",
    "        print(name)\n",
    "\n",
    "    # Access and print the contents of individual datasets\n",
    "    print(\"\\nContents of 'time_steps' dataset:\")\n",
    "    time_steps_dataset = file['time_steps']\n",
    "    print(time_steps_dataset[:])  # Print all values\n",
    "\n",
    "    print(\"\\nContents of 'a' dataset:\")\n",
    "    a_dataset = file['a']\n",
    "    print(a_dataset[:])  # Print all values\n",
    "\n",
    "    print(\"\\nContents of 'b' dataset:\")\n",
    "    b_dataset = file['b']\n",
    "    print(b_dataset[:])  # Print all values\n",
    "\n",
    "    print(\"\\nContents of 'c' dataset:\")\n",
    "    c_dataset = file['c']\n",
    "    print(c_dataset[:])  # Print all values\n",
    "\n",
    "    print(\"\\nContents of 'd' dataset:\")\n",
    "    d_dataset = file['d']\n",
    "    print(d_dataset[:])  # Print all values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6c777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
